{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoJPavCXqZIId+4rfd/+vn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JMandal02/Data-Science_pwskills/blob/main/CNN_Architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1  \n",
        "**What is the role of filters and feature maps in Convolutional Neural\n",
        "Network (CNN)?**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "In a Convolutional Neural Network (CNN), **filters (kernels)** and **feature maps** are fundamental components responsible for automatic feature extraction from input data such as images.\n",
        "\n",
        "**Filters (Kernels):**  \n",
        "A filter is a small matrix of learnable weights (for example, 3×3 or 5×5) that slides over the input image. Each filter is designed to detect a specific type of feature such as edges, corners, textures, or patterns. During convolution, the filter performs element-wise multiplication with the input region and produces a single output value.\n",
        "\n",
        "**Feature Maps:**  \n",
        "The result of applying a filter over the entire input image is called a **feature map**. Each feature map highlights the presence and location of the specific feature detected by the filter. Multiple filters generate multiple feature maps, allowing the CNN to learn various features simultaneously.\n",
        "\n",
        "**Role in CNN:**  \n",
        "- Enable automatic feature extraction\n",
        "- Preserve spatial relationships in images\n",
        "- Reduce manual feature engineering\n",
        "- Help the network learn hierarchical features (low-level to high-level)\n",
        "\n",
        "Thus, filters act as feature detectors, and feature maps store the detected features across the image.\n"
      ],
      "metadata": {
        "id": "id7LPridXTmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2  \n",
        "**Explain the concepts of padding and stride in CNNs(Convolutional Neural\n",
        "Network). How do they affect the output dimensions of feature maps?**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "**Padding:**  \n",
        "Padding refers to adding extra pixels (usually zeros) around the border of the input image before applying convolution. Padding helps control the spatial size of the output feature map.\n",
        "\n",
        "Types of padding:\n",
        "- **Valid padding:** No padding; output size decreases\n",
        "- **Same padding:** Padding added so output size remains the same as input\n",
        "\n",
        "**Stride:**  \n",
        "Stride defines the number of pixels by which the filter moves over the input image.  \n",
        "- Stride = 1 → filter moves one pixel at a time\n",
        "- Stride > 1 → filter skips pixels, reducing output size\n",
        "\n",
        "**Effect on Output Dimensions:**  \n",
        "The output size of a feature map is calculated as:\n",
        "\n",
        "$$\\text{Output} = \\frac{N - F + 2P}{S} + 1$$\n",
        "\n",
        "Where:  \n",
        "- \\(N\\) = input size  \n",
        "- \\(F\\) = filter size  \n",
        "- \\(P\\) = padding  \n",
        "- \\(S\\) = stride  \n",
        "\n",
        "**Impact:**  \n",
        "- Padding preserves spatial information  \n",
        "- Larger stride reduces feature map size and computation  \n",
        "- Proper choice balances accuracy and efficiency\n"
      ],
      "metadata": {
        "id": "sKQyI-mRXa2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3  \n",
        "**Define receptive field in the context of CNNs. Why is it important for deep\n",
        "architectures?**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "The **receptive field** of a neuron in a CNN refers to the region of the input image that influences that neuron's output.\n",
        "\n",
        "In early layers, neurons have small receptive fields and capture local features like edges. As the network goes deeper, receptive fields grow larger, enabling neurons to capture more global and complex features such as objects or shapes.\n",
        "\n",
        "**Importance in Deep Architectures:**  \n",
        "- Enables hierarchical feature learning  \n",
        "- Helps capture context and spatial dependencies  \n",
        "- Larger receptive fields allow understanding of entire objects  \n",
        "- Improves performance in complex image recognition tasks  \n",
        "\n",
        "Deep CNNs rely on increasing receptive fields to move from low-level to high-level understanding.\n"
      ],
      "metadata": {
        "id": "e9nYyfnbYUsF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4  \n",
        "**Discuss how filter size and stride influence the number of parameters in a\n",
        "CNN.**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "**Filter Size:**  \n",
        "Larger filters contain more weights, increasing the number of trainable parameters.  \n",
        "For example:\n",
        "- 3×3 filter → 9 parameters per channel\n",
        "- 5×5 filter → 25 parameters per channel\n",
        "\n",
        "**Stride:**  \n",
        "Stride does not directly affect the number of parameters but impacts the output feature map size. Larger strides reduce spatial dimensions, lowering computation in subsequent layers.\n",
        "\n",
        "**Parameter Formula:**  \n",
        "$$\\text{Parameters} = ((\\text{Filter Height} \\times \\text{Filter Width} \\times \\text{Input Channels}) + 1) \\times \\text{Number of Filters}$$\n",
        "\n",
        "**Impact Summary:**  \n",
        "- Larger filters → more parameters and higher computational cost  \n",
        "- Smaller filters (e.g., 3×3) are preferred for efficiency  \n",
        "- Higher stride → reduced feature map size and faster computation  \n",
        "\n",
        "Modern CNNs use small filters with deeper architectures for better performance.\n"
      ],
      "metadata": {
        "id": "ycGunX4yYWRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5  \n",
        "**Compare and contrast different CNN-based architectures like LeNet,\n",
        "AlexNet, and VGG in terms of depth, filter sizes, and performance.**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "| Architecture | Depth | Filter Size | Performance |\n",
        "|-------------|------|-------------|------------|\n",
        "| LeNet | Shallow (5 layers) | Large (5×5) | Suitable for simple datasets like MNIST |\n",
        "| AlexNet | Medium (8 layers) | Mixed (11×11, 5×5, 3×3) | Breakthrough performance on ImageNet |\n",
        "| VGG | Deep (16–19 layers) | Small (3×3) | High accuracy, high computation |\n",
        "\n",
        "**Key Differences:**  \n",
        "- LeNet is simple and lightweight  \n",
        "- AlexNet introduced ReLU, dropout, and GPU training  \n",
        "- VGG focuses on depth with uniform small filters  \n",
        "\n",
        "VGG achieves better accuracy at the cost of higher memory and computation.\n"
      ],
      "metadata": {
        "id": "5B2TutkEYrTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6  \n",
        "**Using keras, build and train a simple CNN model on the MNIST dataset\n",
        "from scratch. Include code for module creation, compilation, training, and evaluation.**\n",
        "\n",
        "**Answer:**  "
      ],
      "metadata": {
        "id": "bLGPqUq8YwOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 1. Load and Preprocess Data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1] and add channel dimension (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train.astype(\"float32\") / 255, -1)\n",
        "x_test = np.expand_dims(x_test.astype(\"float32\") / 255, -1)\n",
        "\n",
        "# One-hot encode the labels (0-9)\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Build the CNN Model\n",
        "model = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28, 1)),\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# 3. Compile and Train\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1, verbose=1)\n",
        "\n",
        "# 4. Evaluate and Plot Results\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"\\nTest loss: {score[0]:.4f}\")\n",
        "print(f\"Test accuracy: {score[1]:.4f}\")\n",
        "\n",
        "# Optional: Plot training history\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "RtoTWxGkbMEg",
        "outputId": "a6b41eb4-4093-41ff-dea3-0a863c58a024"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Starting training...\n",
            "Epoch 1/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.7725 - loss: 0.7388 - val_accuracy: 0.9755 - val_loss: 0.0853\n",
            "Epoch 2/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9612 - loss: 0.1247 - val_accuracy: 0.9855 - val_loss: 0.0579\n",
            "Epoch 3/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.0928 - val_accuracy: 0.9867 - val_loss: 0.0502\n",
            "Epoch 4/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0729 - val_accuracy: 0.9888 - val_loss: 0.0444\n",
            "Epoch 5/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0668 - val_accuracy: 0.9897 - val_loss: 0.0402\n",
            "Epoch 6/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.0618 - val_accuracy: 0.9892 - val_loss: 0.0359\n",
            "Epoch 7/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0519 - val_accuracy: 0.9910 - val_loss: 0.0361\n",
            "Epoch 8/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0472 - val_accuracy: 0.9912 - val_loss: 0.0340\n",
            "Epoch 9/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0466 - val_accuracy: 0.9912 - val_loss: 0.0355\n",
            "Epoch 10/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0408 - val_accuracy: 0.9915 - val_loss: 0.0337\n",
            "\n",
            "Test loss: 0.0275\n",
            "Test accuracy: 0.9906\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7  \n",
        "**Load and preprocess the CIFAR-10 dataset using Keras, and create a\n",
        "CNN model to classify RGB images. Show your preprocessing and architecture.**\n",
        "\n",
        "**Answer:**  \n"
      ],
      "metadata": {
        "id": "KlPEY7NmcDAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load and Preprocess Data\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# 2. Define the Architecture\n",
        "model = models.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Classification Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10) # 10 output classes for CIFAR-10\n",
        "])\n",
        "\n",
        "# 3. Compile and Train\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"Starting training on CIFAR-10...\")\n",
        "history = model.fit(train_images, train_labels, epochs=10,\n",
        "                    validation_data=(test_images, test_labels))\n",
        "\n",
        "# 4. Summary of Model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "uFA67GUeY0mQ",
        "outputId": "e5e3f13a-c5ea-4b84-e4b4-ee1f67993eb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on CIFAR-10...\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.3622 - loss: 1.7292 - val_accuracy: 0.5512 - val_loss: 1.2481\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.5760 - loss: 1.1920 - val_accuracy: 0.6157 - val_loss: 1.0853\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6407 - loss: 1.0102 - val_accuracy: 0.6203 - val_loss: 1.0845\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6814 - loss: 0.9080 - val_accuracy: 0.6693 - val_loss: 0.9410\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7137 - loss: 0.8100 - val_accuracy: 0.6687 - val_loss: 0.9369\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.7562 - val_accuracy: 0.6908 - val_loss: 0.8958\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.7005 - val_accuracy: 0.7003 - val_loss: 0.8928\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.6455 - val_accuracy: 0.7088 - val_loss: 0.8732\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7895 - loss: 0.6002 - val_accuracy: 0.7160 - val_loss: 0.8596\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8038 - loss: 0.5574 - val_accuracy: 0.7092 - val_loss: 0.9021\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m65,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m367,712\u001b[0m (1.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">367,712</span> (1.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,570\u001b[0m (478.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,570</span> (478.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m245,142\u001b[0m (957.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,142</span> (957.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8  \n",
        "**Using PyTorch, write a script to define and train a CNN on the MNIST\n",
        "dataset. Include model definition, data loaders, training loop, and accuracy evaluation.**\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "VJVDnnDecbPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Define the CNN Architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Formula: Output = ((N - F + 2P) / S) + 1\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) # In: 28x28, Out: 26x26\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # In: 13x13 (after pool), Out: 11x11\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 128) # After 2 pools, 28->13->5\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 5 * 5) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 2. Setup Data, Device, and Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "train_loader = DataLoader(datasets.MNIST('./data', train=True, download=True, transform=transform), batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(datasets.MNIST('./data', train=False, transform=transform), batch_size=1000)\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 3. Training Loop\n",
        "def train(epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)}] Loss: {loss.item():.4f}')\n",
        "\n",
        "# 4. Evaluation\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    print(f'\\nTest Accuracy: {100. * correct / len(test_loader.dataset):.2f}%')\n",
        "\n",
        "train(3)\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfvYtxoKcAr7",
        "outputId": "49658825-f11e-48ff-c570-a1b6e769f527"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 426kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.97MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 13.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 [0/60000] Loss: 2.3168\n",
            "Epoch 0 [6400/60000] Loss: 0.0957\n",
            "Epoch 0 [12800/60000] Loss: 0.0764\n",
            "Epoch 0 [19200/60000] Loss: 0.0409\n",
            "Epoch 0 [25600/60000] Loss: 0.1078\n",
            "Epoch 0 [32000/60000] Loss: 0.0698\n",
            "Epoch 0 [38400/60000] Loss: 0.0240\n",
            "Epoch 0 [44800/60000] Loss: 0.0576\n",
            "Epoch 0 [51200/60000] Loss: 0.1086\n",
            "Epoch 0 [57600/60000] Loss: 0.0490\n",
            "Epoch 1 [0/60000] Loss: 0.0356\n",
            "Epoch 1 [6400/60000] Loss: 0.0401\n",
            "Epoch 1 [12800/60000] Loss: 0.0236\n",
            "Epoch 1 [19200/60000] Loss: 0.0139\n",
            "Epoch 1 [25600/60000] Loss: 0.0842\n",
            "Epoch 1 [32000/60000] Loss: 0.0604\n",
            "Epoch 1 [38400/60000] Loss: 0.0032\n",
            "Epoch 1 [44800/60000] Loss: 0.0279\n",
            "Epoch 1 [51200/60000] Loss: 0.0320\n",
            "Epoch 1 [57600/60000] Loss: 0.0237\n",
            "Epoch 2 [0/60000] Loss: 0.0206\n",
            "Epoch 2 [6400/60000] Loss: 0.0136\n",
            "Epoch 2 [12800/60000] Loss: 0.0496\n",
            "Epoch 2 [19200/60000] Loss: 0.0088\n",
            "Epoch 2 [25600/60000] Loss: 0.0310\n",
            "Epoch 2 [32000/60000] Loss: 0.0414\n",
            "Epoch 2 [38400/60000] Loss: 0.0183\n",
            "Epoch 2 [44800/60000] Loss: 0.0092\n",
            "Epoch 2 [51200/60000] Loss: 0.0049\n",
            "Epoch 2 [57600/60000] Loss: 0.0262\n",
            "\n",
            "Test Accuracy: 99.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9  \n",
        "**Given a custom image dataset stored in a local directory, write code using\n",
        "Keras ImageDataGenerator to preprocess and train a CNN model.**"
      ],
      "metadata": {
        "id": "CDTgWLLWiMEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Setup Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Automatic splitting\n",
        ")\n",
        "\n",
        "# Flow from the downloaded directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# 2. Build CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. Compile and Train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training on local directory...\")\n",
        "model.fit(train_generator, epochs=5, validation_data=validation_generator)\n",
        "\n",
        "# 4. Summary of Model\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "5cQWozMxfZxM",
        "outputId": "180678a1-cb0f-420f-d33b-156f9ca01e5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2936 images belonging to 1 classes.\n",
            "Found 734 images belonging to 1 classes.\n",
            "Training on local directory...\n",
            "Epoch 1/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 254ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82944\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m5,308,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82944</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,308,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,983,813\u001b[0m (60.97 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,983,813</span> (60.97 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,327,937\u001b[0m (20.32 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,327,937</span> (20.32 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,655,876\u001b[0m (40.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,655,876</span> (40.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question  \n",
        "**You are working on a web application for a medical imaging startup. Your task is to build and deploy a CNN model that classifies chest X-ray images into “Normal” and “Pneumonia” categories. Describe your end-to-end approach—from data preparation and model training to deploying the model as a web app using Streamlit.**\n",
        "\n",
        "**Answer:**  \n",
        "\n",
        "The development of a chest X-ray classification system using a Convolutional Neural Network (CNN) involves a complete end-to-end pipeline, starting from data preparation to deployment as a web application using Streamlit.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Data Collection and Preparation  \n",
        "\n",
        "Chest X-ray images are collected from reliable medical datasets or hospital repositories and labeled into two categories: **Normal** and **Pneumonia**.  \n",
        "The dataset is organized in a directory structure suitable for deep learning frameworks:\n",
        "\n",
        "\n",
        "This structure allows automatic label assignment during training.\n",
        "\n",
        "### **Dataset Directory Structure**\n",
        "This structure allows automatic label assignment during training:\n",
        "\n",
        "```text\n",
        "dataset/\n",
        "├── train/\n",
        "│   ├── Normal/\n",
        "│   └── Pneumonia/\n",
        "├── validation/\n",
        "│   ├── Normal/\n",
        "│   └── Pneumonia/\n",
        "└── test/\n",
        "    ├── Normal/\n",
        "    └── Pneumonia/\n",
        "```\n",
        "\n",
        "### 2. Data Preprocessing and Augmentation  \n",
        "\n",
        "Medical images vary in resolution, brightness, and quality. To improve model robustness, preprocessing is applied:\n",
        "- Resizing images to a fixed size (e.g., 224×224)\n",
        "- Normalizing pixel values to the range [0, 1]\n",
        "- Applying data augmentation such as rotation, zoom, and horizontal flipping  \n",
        "\n",
        "Keras `ImageDataGenerator` is used to handle preprocessing and augmentation efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. CNN Model Design and Training  \n",
        "\n",
        "A CNN model is designed to extract spatial features from chest X-ray images.  \n",
        "The architecture typically includes:\n",
        "- Convolutional layers with ReLU activation for feature extraction  \n",
        "- MaxPooling layers to reduce spatial dimensions  \n",
        "- Fully connected Dense layers for classification  \n",
        "- A Sigmoid output layer for binary classification  \n",
        "\n",
        "The model is compiled using:\n",
        "- **Loss function:** Binary Crossentropy  \n",
        "- **Optimizer:** Adam  \n",
        "- **Evaluation metric:** Accuracy  \n",
        "\n",
        "Training is performed on the training dataset, while validation data is used to monitor performance and avoid overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Model Evaluation and Optimization  \n",
        "\n",
        "The trained model is evaluated on unseen test data using:\n",
        "- Accuracy\n",
        "- Precision and Recall\n",
        "- Confusion Matrix  \n",
        "\n",
        "Performance can be further improved using techniques such as dropout, batch normalization, or transfer learning with pretrained models like MobileNet or ResNet.  \n",
        "After final tuning, the trained model is saved as a `.h5` file.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Streamlit Web Application Development  \n",
        "\n",
        "Streamlit is used to build an interactive web interface.  \n",
        "The application allows users to:\n",
        "- Upload chest X-ray images  \n",
        "- Automatically preprocess the uploaded image  \n",
        "- Load the trained CNN model  \n",
        "- Display prediction results as **Normal** or **Pneumonia** along with confidence score  \n",
        "\n",
        "This provides real-time inference in a user-friendly manner.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. Deployment  \n",
        "\n",
        "The Streamlit application is deployed using platforms such as **Streamlit Cloud** or cloud services like AWS or Azure.  \n",
        "Deployment steps include:\n",
        "- Creating a `requirements.txt` file  \n",
        "- Uploading the trained model and app script  \n",
        "- Hosting the application for public or internal access  \n",
        "\n"
      ],
      "metadata": {
        "id": "7MLW4NBzixMh"
      }
    }
  ]
}